{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import zscore\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_rel, ttest_ind, wilcoxon\n",
    "rng = np.random.default_rng()\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from patsy.contrasts import Treatment\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"transformed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "# List of variables for summary stats\n",
    "summary_vars = [\n",
    "    'Age', 'Gender', 'High_wealth', 'Own_asset', 'Intere_inves',\n",
    "    'Trade_frequently', 'numcorrect_financialliteracyall', 'Risk_taking',\n",
    "    'Patient', 'Share_willing', 'Donate_charity', 'Donation',\n",
    "    'Sustainability_Value', 'correct_Environ_Literacy', 'High_CurrentSustainShare',\n",
    "    'Invest_in_SRI', 'correct_comprehension', 'Stat_know',\n",
    "    'Number_think', 'Number_inter'\n",
    "]\n",
    "\n",
    "# Summary stats by treatment_num\n",
    "summary_table = df[summary_vars + ['treatment_num']].groupby('treatment_num').agg(\n",
    "    ['count', 'mean', 'std', 'min', 'max']\n",
    ")\n",
    "\n",
    "# Flatten column MultiIndex\n",
    "summary_table.columns = ['_'.join(col).strip() for col in summary_table.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map treatment labels to treatments\n",
    "treatment_labels = {\n",
    "    1: \"Baseline\",\n",
    "    2: \"Green\",\n",
    "    3: \"Brown\",\n",
    "    4: \"Green Low\"\n",
    "}\n",
    "\n",
    "# Map treatment_num to label\n",
    "df['treatment_label'] = df['treatment_num'].map(treatment_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T-tests Main Effects Allocations to Assets\n",
    "\n",
    "def run_ttest(df, var, treat_col, group1, group2):\n",
    "    group1_data = df[df[treat_col] == group1][var].dropna()\n",
    "    group2_data = df[df[treat_col] == group2][var].dropna()\n",
    "    \n",
    "    tstat, pval = ttest_ind(group2_data, group1_data, equal_var=False)\n",
    "    diff = group2_data.mean() - group1_data.mean()\n",
    "    \n",
    "    return {\n",
    "        'Variable': var,\n",
    "        'Group 1': treatment_labels[group1],\n",
    "        'Group 2': treatment_labels[group2],\n",
    "        'Mean Group 1': round(group1_data.mean(), 2),\n",
    "        'Mean Group 2': round(group2_data.mean(), 2),\n",
    "        'Difference': round(diff, 2),\n",
    "        'T-Statistic': round(tstat, 2),\n",
    "        'P-Value': round(pval, 4)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    ('HighCorr_investmentAsset_lowret', 1, 2),  # Baseline vs Green (Positive Corr)\n",
    "    ('LowCorr_investmentAsset_lowret', 1, 2),   # Baseline vs Green (Negative Corr)\n",
    "    ('HighCorr_investmentAsset_lowret', 1, 3),  # Baseline vs Brown (Positive Corr)\n",
    "    ('LowCorr_investmentAsset_lowret', 1, 3),   # Baseline vs Brown (Negative Corr)\n",
    "]\n",
    "\n",
    "results = [run_ttest(df, var, 'treatment_num', g1, g2) for var, g1, g2 in tests]\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend the list of variables to test\n",
    "more_tests = [\n",
    "    ('correlation_neglect', 1, 2),\n",
    "    ('correlation_neglect', 1, 3),\n",
    "    ('consider_corr', 1, 2),\n",
    "    ('consider_corr', 1, 3)\n",
    "]\n",
    "\n",
    "# Combine with previous\n",
    "all_tests = tests + more_tests\n",
    "\n",
    "# Run all\n",
    "all_results = [run_ttest(df, var, 'treatment_num', g1, g2) for var, g1, g2 in all_tests]\n",
    "ttest_results_df = pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T-Tests â€” Deviation from Optimal Allocation\n",
    "highcorr_optimal = 23.90\n",
    "lowcorr_optimal = 45.60\n",
    "\n",
    "\n",
    "def ttest_optimal(df, var, optimal_value, treatment):\n",
    "    data = df[df['treatment_num'] == treatment][var].dropna()\n",
    "    tstat, pval = ttest_1samp(data, popmean=optimal_value)\n",
    "    diff = data.mean() - optimal_value\n",
    "\n",
    "    return {\n",
    "        'Variable': var,\n",
    "        'Treatment': treatment_labels.get(treatment, treatment),\n",
    "        'Mean': round(data.mean(), 2),\n",
    "        'Optimal': optimal_value,\n",
    "        'Difference': round(diff, 2),\n",
    "        'T-Statistic': round(tstat, 2),\n",
    "        'P-Value': round(pval, 4)\n",
    "    }\n",
    "\n",
    "optimal_tests = []\n",
    "\n",
    "# Test deviation from optimal for HighCorr\n",
    "for treatment in [1, 2, 3]:\n",
    "    optimal_tests.append(ttest_optimal(df, 'HighCorr_investmentAsset_lowret', highcorr_optimal, treatment))\n",
    "\n",
    "# Test deviation from optimal for LowCorr\n",
    "for treatment in [1, 2, 3]:\n",
    "    optimal_tests.append(ttest_optimal(df, 'LowCorr_investmentAsset_lowret', lowcorr_optimal, treatment))\n",
    "\n",
    "optimal_tests_df = pd.DataFrame(optimal_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_tests_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Effects on Share_lowreturn (T-Tests Low Correlation Scenario)\n",
    "\n",
    "# Filter the data for relevant treatments\n",
    "df_t12 = df[df['treatment_num'].isin([1, 2])]\n",
    "df_t13 = df[df['treatment_num'].isin([1, 3])]\n",
    "\n",
    "# T-test: Treatment 1 vs 2\n",
    "t12_group1 = df_t12[df_t12['treatment_num'] == 1]['Share_lowreturn'].dropna()\n",
    "t12_group2 = df_t12[df_t12['treatment_num'] == 2]['Share_lowreturn'].dropna()\n",
    "t_stat_t12, p_val_t12 = ttest_ind(t12_group1, t12_group2, equal_var=True)\n",
    "\n",
    "# T-test: Treatment 1 vs 3\n",
    "t13_group1 = df_t13[df_t13['treatment_num'] == 1]['Share_lowreturn'].dropna()\n",
    "t13_group2 = df_t13[df_t13['treatment_num'] == 3]['Share_lowreturn'].dropna()\n",
    "t_stat_t13, p_val_t13 = ttest_ind(t13_group1, t13_group2, equal_var=True)\n",
    "\n",
    "print(f\"Treatment 1 vs 2: t = {t_stat_t12:.2f}, p = {p_val_t12:.3f}\")\n",
    "print(f\"Treatment 1 vs 3: t = {t_stat_t13:.2f}, p = {p_val_t13:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Main Treatment Effects (Low Correlation Scenario)\n",
    "\n",
    "# Prepare summary stats\n",
    "grouped = df[df['treatment_num'].isin([1, 2, 3])].groupby('treatment_num')['Share_lowreturn']\n",
    "means = grouped.mean()\n",
    "stds = grouped.std()\n",
    "counts = grouped.count()\n",
    "cis = 1.96 * (stds / np.sqrt(counts))  \n",
    "\n",
    "# Treatment labels\n",
    "labels = ['Baseline', 'Green', 'Brown']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=labels, y=means.values, yerr=cis.values, capsize=0.2, palette='gray')\n",
    "\n",
    "plt.ylabel(\"Share Allocated to Diversification Asset\")\n",
    "plt.title(\"Treatment Effects on Diversification Allocation (Low Corr)\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"treatment_effects_lowcorr.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Effects on Share_lowreturn (T-Tests High Correlation Scenario)\n",
    "# T-test: HighCorr_investmentAsset_lowret (Treatment 1 vs 2 and 1 vs 3)\n",
    "df_t12 = df[df['treatment_num'].isin([1, 2])]\n",
    "df_t13 = df[df['treatment_num'].isin([1, 3])]\n",
    "\n",
    "# T1 vs T2\n",
    "t12_group1 = df_t12[df_t12['treatment_num'] == 1]['HighCorr_investmentAsset_lowret'].dropna()\n",
    "t12_group2 = df_t12[df_t12['treatment_num'] == 2]['HighCorr_investmentAsset_lowret'].dropna()\n",
    "t_stat_t12_pos, p_val_t12_pos = ttest_ind(t12_group1, t12_group2, equal_var=True)\n",
    "\n",
    "# T1 vs T3\n",
    "t13_group1 = df_t13[df_t13['treatment_num'] == 1]['HighCorr_investmentAsset_lowret'].dropna()\n",
    "t13_group2 = df_t13[df_t13['treatment_num'] == 3]['HighCorr_investmentAsset_lowret'].dropna()\n",
    "t_stat_t13_pos, p_val_t13_pos = ttest_ind(t13_group1, t13_group2, equal_var=True)\n",
    "\n",
    "print(f\"Treatment 1 vs 2 (High Corr): t = {t_stat_t12_pos:.2f}, p = {p_val_t12_pos:.3f}\")\n",
    "print(f\"Treatment 1 vs 3 (High Corr): t = {t_stat_t13_pos:.2f}, p = {p_val_t13_pos:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot Main Treatment Effects (High Correlation Scenario)\n",
    "# Prepare summary stats\n",
    "grouped_high = df[df['treatment_num'].isin([1, 2, 3])].groupby('treatment_num')['HighCorr_investmentAsset_lowret']\n",
    "means_high = grouped_high.mean()\n",
    "stds_high = grouped_high.std()\n",
    "counts_high = grouped_high.count()\n",
    "cis_high = 1.96 * (stds_high / np.sqrt(counts_high))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=labels, y=means_high.values, yerr=cis_high.values, capsize=5, palette='gray')\n",
    "\n",
    "plt.ylabel(\"Share Allocated to Diversification Asset\")\n",
    "plt.title(\"Allocation in Positive Correlation Scenario\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment Effects Correlation Neglect\n",
    "# T1 vs T2\n",
    "t12_group1 = df[df['treatment_num'] == 1]['correlation_neglect'].dropna()\n",
    "t12_group2 = df[df['treatment_num'] == 2]['correlation_neglect'].dropna()\n",
    "t_stat_cn_12, p_val_cn_12 = ttest_ind(t12_group1, t12_group2, equal_var=True)\n",
    "\n",
    "# T1 vs T3\n",
    "t13_group1 = df[df['treatment_num'] == 1]['correlation_neglect'].dropna()\n",
    "t13_group2 = df[df['treatment_num'] == 3]['correlation_neglect'].dropna()\n",
    "t_stat_cn_13, p_val_cn_13 = ttest_ind(t13_group1, t13_group2, equal_var=True)\n",
    "\n",
    "print(f\"Treatment 1 vs 2 (Corr Neglect): t = {t_stat_cn_12:.2f}, p = {p_val_cn_12:.3f}\")\n",
    "print(f\"Treatment 1 vs 3 (Corr Neglect): t = {t_stat_cn_13:.2f}, p = {p_val_cn_13:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats\n",
    "grouped_cn = df[df['treatment_num'].isin([1, 2, 3])].groupby('treatment_num')['correlation_neglect']\n",
    "means_cn = grouped_cn.mean()\n",
    "stds_cn = grouped_cn.std()\n",
    "counts_cn = grouped_cn.count()\n",
    "cis_cn = 1.96 * (stds_cn / np.sqrt(counts_cn))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=labels, y=means_cn.values, yerr=cis_cn.values, capsize=0.2, palette='gray')\n",
    "\n",
    "plt.ylabel(\"Correlation Neglect\")\n",
    "plt.title(\"Correlation Neglect Across Treatments\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.ylim(0, None)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression Models Main Effects Allocations\n",
    "# Ensure consistent treatment coding \n",
    "df['treatment_num'] = pd.Categorical(df['treatment_num'], categories=[1, 2, 3], ordered=True)\n",
    "\n",
    "# Define helper function to run clustered regression with correct treatment baseline\n",
    "def run_regression(df, dependent_var, independent_vars, treatment_col, id_col):\n",
    "    formula = f\"{dependent_var} ~ {' + '.join(independent_vars)} + C({treatment_col}, Treatment(reference=1)) * High_Corr\"\n",
    "    model = smf.ols(formula, data=df).fit(cov_type='cluster', cov_kwds={'groups': df[id_col]})\n",
    "    return model\n",
    "\n",
    "# Define independent variables for the regression\n",
    "independent_vars = [\n",
    "    'Age', 'Gender', 'High_wealth', 'Patient', 'Risk_taking', 'Social_Preferences',\n",
    "    'Donation', 'Sustainability_Value', 'numcorrect_financialliteracyall',\n",
    "    'correct_Environ_Literacy', 'Stat_know', 'Number_think', 'Number_inter',\n",
    "    'Own_asset', 'Intere_inves', 'Trade_frequently', 'High_CurrentSustainShare'\n",
    "]\n",
    "\n",
    "# Create High_Corr and Share_lowreturn variables\n",
    "df['dup'] = np.tile([0, 1], len(df) // 2)\n",
    "df['First_Round'] = np.where(df['dup'] == 0, 1, 0)\n",
    "df['Second_Round'] = np.where(df['dup'] == 1, 1, 0)\n",
    "\n",
    "df['High_Corr'] = np.where(\n",
    "    (df['First_Round'] == 1) & (df['P1_low_first'] == 0), 1,\n",
    "    np.where(\n",
    "        (df['First_Round'] == 1) & (df['P1_low_first'] == 1), 0,\n",
    "        np.where((df['First_Round'] == 0) & (df['P1_low_first'] == 1), 1, 0)\n",
    "    )\n",
    ")\n",
    "\n",
    "df['Share_lowreturn'] = np.where(\n",
    "    df['First_Round'] == 1,\n",
    "    df['P1_investmentAsset_lowreturn'],\n",
    "    df['P2_investmentAsset_lowreturn']\n",
    ")\n",
    "\n",
    "# Subset and fix categorical levels for green vs baseline\n",
    "df_green = df[df['treatment_num'].isin([1, 2])].copy()\n",
    "df_green['treatment_num'] = pd.Categorical(df_green['treatment_num'], categories=[1, 2], ordered=True)\n",
    "\n",
    "# Subset and fix categorical levels for brown vs baseline\n",
    "df_brown = df[df['treatment_num'].isin([1, 3])].copy()\n",
    "df_brown['treatment_num'] = pd.Categorical(df_brown['treatment_num'], categories=[1, 3], ordered=True)\n",
    "\n",
    "# Run regressions\n",
    "model_green = run_regression(df_green, 'Share_lowreturn', independent_vars, 'treatment_num', 'id')\n",
    "model_brown = run_regression(df_brown, 'Share_lowreturn', independent_vars, 'treatment_num', 'id')\n",
    "\n",
    "# Combine into LaTeX regression table\n",
    "main_effects_table = summary_col(\n",
    "    [model_green, model_brown],\n",
    "    stars=True,\n",
    "    model_names=[\"Green vs Baseline\", \"Brown vs Baseline\"],\n",
    "    info_dict={\n",
    "        'R-squared': lambda x: f\"{x.rsquared:.2f}\",\n",
    "        'N': lambda x: f\"{int(x.nobs)}\"\n",
    "    },\n",
    "    float_format=\"%.2f\"\n",
    ")\n",
    "\n",
    "# Print and save LaTeX\n",
    "latex_main = main_effects_table.as_latex()\n",
    "print(latex_main)\n",
    "\n",
    "with open(\"main_effects_regression_results.tex\", \"w\") as f:\n",
    "    f.write(latex_main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common control variables\n",
    "controls = [\n",
    "    \"Age\", \"Gender\", \"High_wealth\", \"Patient\", \"Risk_taking\", \"Social_Preferences\", \n",
    "    \"Donation\", \"Sustainability_Value\", \"numcorrect_financialliteracyall\", \n",
    "    \"correct_Environ_Literacy\", \"Stat_know\", \"Number_think\", \"Number_inter\", \n",
    "    \"Own_asset\", \"Intere_inves\", \"Trade_frequently\", \"High_CurrentSustainShare\", \n",
    "    \"correct_comprehension\", \"correct_dependence\", \"P1_high_return\"\n",
    "]\n",
    "\n",
    "# Construct control string\n",
    "control_str = \" + \".join(controls)\n",
    "\n",
    "# Create Lower_Bound, Upper_Bound, Expect_value based on First_Round\n",
    "df[\"Expect_value\"] = df[\"P1_Expect_value\"].where(df[\"First_Round\"] == 1, df[\"P2_Expect_value\"])\n",
    "df[\"Lower_Bound\"] = df[\"P1_belief_lower\"].where(df[\"First_Round\"] == 1, df[\"P2_belief_lower\"])\n",
    "df[\"Upper_Bound\"] = df[\"P1_belief_upper\"].where(df[\"First_Round\"] == 1, df[\"P2_belief_upper\"])\n",
    "\n",
    "\n",
    "# Treatment interaction\n",
    "treatment_interaction = \"C(treatment_num)*High_Corr + First_Round*High_Corr\"\n",
    "\n",
    "# Final formula function\n",
    "def make_formula(y_var):\n",
    "    return f\"{y_var} ~ {treatment_interaction} + {control_str}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Green sample\n",
    "df_green = df[df['treatment_num'].isin([1, 2])]\n",
    "\n",
    "model_lower_green = smf.ols(make_formula(\"Lower_Bound\"), data=df_green).fit(cov_type='cluster', cov_kwds={'groups': df_green[\"id\"]})\n",
    "model_upper_green = smf.ols(make_formula(\"Upper_Bound\"), data=df_green).fit(cov_type='cluster', cov_kwds={'groups': df_green[\"id\"]})\n",
    "model_expect_green = smf.ols(make_formula(\"Expect_value\"), data=df_green).fit(cov_type='cluster', cov_kwds={'groups': df_green[\"id\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Brown sample\n",
    "df_brown = df[df['treatment_num'].isin([1, 3])]\n",
    "\n",
    "model_lower_brown = smf.ols(make_formula(\"Lower_Bound\"), data=df_brown).fit(cov_type='cluster', cov_kwds={'groups': df_brown[\"id\"]})\n",
    "model_upper_brown = smf.ols(make_formula(\"Upper_Bound\"), data=df_brown).fit(cov_type='cluster', cov_kwds={'groups': df_brown[\"id\"]})\n",
    "model_expect_brown = smf.ols(make_formula(\"Expect_value\"), data=df_brown).fit(cov_type='cluster', cov_kwds={'groups': df_brown[\"id\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "belief_models = {\n",
    "    \"Lower_Bound_Green\": model_lower_green,\n",
    "    \"Upper_Bound_Green\": model_upper_green,\n",
    "    \"Expected_Value_Green\": model_expect_green,\n",
    "    \"Lower_Bound_Brown\": model_lower_brown,\n",
    "    \"Upper_Bound_Brown\": model_upper_brown,\n",
    "    \"Expected_Value_Brown\": model_expect_brown,\n",
    "} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the regression models for output\n",
    "belief_table = summary_col(\n",
    "    list(belief_models.values()),\n",
    "    stars=True,\n",
    "    model_names=list(belief_models.keys()),\n",
    "    info_dict={\n",
    "        'R-squared': lambda x: f\"{x.rsquared:.2f}\",\n",
    "        'N': lambda x: f\"{int(x.nobs)}\"\n",
    "    },\n",
    "    float_format=\"%.2f\"\n",
    ")\n",
    "\n",
    "# Print the LaTeX output\n",
    "latex_belief = belief_table.as_latex()\n",
    "print(latex_belief)\n",
    "\n",
    "# Save to file\n",
    "with open(\"beliefs_regression_results.tex\", \"w\") as f:\n",
    "    f.write(latex_belief)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
